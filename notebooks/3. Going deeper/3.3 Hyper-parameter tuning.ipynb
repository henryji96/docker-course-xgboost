{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"width:100%\" src=\"../images/practical_xgboost_in_python_notebook_header.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning\n",
    "\n",
    "As you know there are plenty of tunable parameters. Each one results in different output. The question is which combination results in best output.\n",
    "\n",
    "The following notebook will show you how to use Scikit-learn modules for figuring out the best parameters for your  models.\n",
    "\n",
    "**What's included:**\n",
    "- <a href=\"#data\">data preparation</a>,\n",
    "- <a href=\"#grid\">finding best hyper-parameters using grid-search</a>,\n",
    "- <a href=\"#rgrid\">finding best hyper-parameters using randomized grid-search<a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data<a name='data' />\n",
    "Let's begin with loading all required libraries in one place and setting seed number for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# reproducibility\n",
    "seed = 342\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate artificial dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=8, n_redundant=3, n_repeated=2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cross-validation strategy for testing. Let's use `StratifiedKFold` which guarantees that target label is equally distributed across each fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-Search<a name='grid' />\n",
    "In grid-search we start by defining a dictionary holding possible parameter values we want to test. **All** combinations will be evaluted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'max_depth': [1, 2, 3],\n",
    "    'n_estimators': [5, 10, 25, 50],\n",
    "    'learning_rate': np.linspace(1e-16, 1, 3)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a dictionary for fixed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_fixed = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `GridSearchCV` estimator. We will be looking for combination giving the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst_grid = GridSearchCV(\n",
    "    estimator=XGBClassifier(**params_fixed, seed=seed),\n",
    "    param_grid=params_grid,\n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=seed),\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the calculations notice that $3*4*3*10=360$ models will be created to test all combinations. You should always have rough estimations about what is going to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=342, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=342, silent=1,\n",
       "       subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': array([  1.00000e-16,   5.00000e-01,   1.00000e+00]), 'n_estimators': [5, 10, 25, 50], 'max_depth': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also keep in mind that train() will return a model from the last iteration, not the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can look at all obtained scores, and try to manually see what matters and what not. A quick glance looks that the largeer `n_estimators` then the accuracy is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy obtained: 0.877\n",
      "Parameters:\n",
      "\tlearning_rate: 0.5\n",
      "\tn_estimators: 50\n",
      "\tmax_depth: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Best accuracy obtained: {0}\".format(bst_grid.best_score_))\n",
    "print(\"Parameters:\")\n",
    "for key, value in bst_grid.best_params_.items():\n",
    "    print(\"\\t{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are many results, we can filter them manually to get the best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005248</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 5, 'm...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006362</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 10, '...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012106</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 25, '...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022464</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 50, '...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 5, 'm...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009224</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 10, '...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.020551</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 25, '...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.039951</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 50, '...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007590</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 5, 'm...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 10, '...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.030066</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 25, '...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.059057</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>1e-16</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1e-16, 'n_estimators': 50, '...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.503885</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003832</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.829444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 5, 'max...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.837597</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.833148</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.834260</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.834444</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.841287</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.817980</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.841287</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.817980</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.049141</td>\n",
       "      <td>0.010958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.839331</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 10, 'ma...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.842047</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.840934</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.853170</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.824249</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.851111</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.847947</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.841287</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.844617</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.843507</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.062425</td>\n",
       "      <td>0.013814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.012112</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.858775</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 25, 'ma...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.855395</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.850945</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.855395</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.850945</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.864444</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.856826</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.860155</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.859046</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.859046</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.048257</td>\n",
       "      <td>0.006819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.022031</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.879777</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50, 'ma...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.875417</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.875417</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.878754</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.879867</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.887778</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.881111</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.876804</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.883463</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.879023</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.880133</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.036066</td>\n",
       "      <td>0.003577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.850220</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 5, 'max...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.835373</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.848721</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.853170</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.847608</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.850166</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.853496</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.852386</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.055117</td>\n",
       "      <td>0.005701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.871220</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 10, 'ma...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.866518</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.869855</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.867631</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.866518</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.866815</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.885683</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.873474</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.866815</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.050756</td>\n",
       "      <td>0.005854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.020994</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.920776</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 25, 'ma...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.922136</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.915462</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.912125</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.925473</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.926748</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.922309</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.928968</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.912320</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.035380</td>\n",
       "      <td>0.005535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.040192</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50, 'ma...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.963293</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.969967</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.970033</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.963374</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.974473</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.960044</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.027401</td>\n",
       "      <td>0.005022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.889108</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 5, 'max...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.886541</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.879867</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.888765</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.887653</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.896781</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.897891</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.889012</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.047832</td>\n",
       "      <td>0.005454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.013525</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.918331</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 10, 'ma...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.907675</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.911012</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.924360</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.921023</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.912222</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.913430</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.917869</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.927858</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.034041</td>\n",
       "      <td>0.006530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.029832</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.976445</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 25, 'ma...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.978865</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.976641</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.977753</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.974416</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.981111</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.974444</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.977802</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.976693</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.968923</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.977802</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.057865</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 50, 'ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.998890</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.998890</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.024129</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.826885</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 5, 'max...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.819800</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.816463</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.823137</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.819800</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.820200</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.837958</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.827969</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.042362</td>\n",
       "      <td>0.008910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.005891</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.842889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 10, 'ma...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.845384</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.842047</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.849833</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.842047</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.841287</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.853496</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.837958</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.841287</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.042541</td>\n",
       "      <td>0.005822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.011767</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.876889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 25, 'ma...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.869855</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.882091</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.874305</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.875417</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>0.874584</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.880133</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.875694</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.872364</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.046201</td>\n",
       "      <td>0.004685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.022429</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.900553</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 50, 'ma...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.892102</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.892102</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.897664</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.898889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.904550</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.903441</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.897891</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.039004</td>\n",
       "      <td>0.005548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.005655</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.864105</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 5, 'max...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.850945</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.831683</td>\n",
       "      <td>0.854283</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.856507</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.870144</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.885683</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.854606</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.041684</td>\n",
       "      <td>0.010470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.901997</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 10, 'ma...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.894327</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.909900</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.895439</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.884316</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.908889</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.904550</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.908990</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.906770</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.891232</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.023829</td>\n",
       "      <td>0.009499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.960555</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 25, 'ma...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.958843</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.961068</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.953281</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.964444</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.957825</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.965594</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.956715</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.003830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.039643</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.994666</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 50, 'ma...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.996663</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.995551</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.992214</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.988877</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.994451</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.996670</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.996670</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.994451</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.024027</td>\n",
       "      <td>0.002377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.907111</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 5, 'max...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.911012</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.908788</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.917778</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.912222</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.913430</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.900111</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.916759</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.891232</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.031309</td>\n",
       "      <td>0.008478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.013244</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.951668</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 10, 'ma...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.959956</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.946607</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.946607</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.952169</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.961111</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.958889</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.947836</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.947836</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.948946</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.946726</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.005680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.029642</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.998666</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 25, 'ma...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.997775</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.995551</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.997780</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.998890</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.998890</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.055487</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 50, 'ma...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_learning_rate param_max_depth param_n_estimators                                             params  rank_test_score  split0_test_score  split0_train_score  split1_test_score  split1_train_score  split2_test_score  split2_train_score  split3_test_score  split3_train_score  split4_test_score  split4_train_score  split5_test_score  split5_train_score  split6_test_score  split6_train_score  split7_test_score  split7_train_score  split8_test_score  split8_train_score  split9_test_score  split9_train_score  std_fit_time  std_score_time  std_test_score  std_train_score\n",
       "0        0.005248         0.000492            0.504          0.504000               1e-16               1                  5  {'learning_rate': 1e-16, 'n_estimators': 5, 'm...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.001018        0.000135        0.002000         0.000222\n",
       "1        0.006362         0.000390            0.504          0.504000               1e-16               1                 10  {'learning_rate': 1e-16, 'n_estimators': 10, '...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.000646        0.000124        0.002000         0.000222\n",
       "2        0.012106         0.000375            0.504          0.504000               1e-16               1                 25  {'learning_rate': 1e-16, 'n_estimators': 25, '...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.000371        0.000051        0.002000         0.000222\n",
       "3        0.022464         0.000432            0.504          0.504000               1e-16               1                 50  {'learning_rate': 1e-16, 'n_estimators': 50, '...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.000557        0.000094        0.002000         0.000222\n",
       "4        0.005491         0.000329            0.504          0.504000               1e-16               2                  5  {'learning_rate': 1e-16, 'n_estimators': 5, 'm...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.000142        0.000055        0.002000         0.000222\n",
       "5        0.009224         0.000325            0.504          0.504000               1e-16               2                 10  {'learning_rate': 1e-16, 'n_estimators': 10, '...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.000135        0.000013        0.002000         0.000222\n",
       "6        0.020551         0.000392            0.504          0.504000               1e-16               2                 25  {'learning_rate': 1e-16, 'n_estimators': 25, '...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.000376        0.000029        0.002000         0.000222\n",
       "7        0.039951         0.000431            0.504          0.504000               1e-16               2                 50  {'learning_rate': 1e-16, 'n_estimators': 50, '...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.001047        0.000018        0.002000         0.000222\n",
       "8        0.007590         0.000327            0.504          0.504000               1e-16               3                  5  {'learning_rate': 1e-16, 'n_estimators': 5, 'm...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.000790        0.000033        0.002000         0.000222\n",
       "9        0.012943         0.000372            0.504          0.504000               1e-16               3                 10  {'learning_rate': 1e-16, 'n_estimators': 10, '...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.000298        0.000044        0.002000         0.000222\n",
       "10       0.030066         0.000413            0.504          0.504000               1e-16               3                 25  {'learning_rate': 1e-16, 'n_estimators': 25, '...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.001354        0.000014        0.002000         0.000222\n",
       "11       0.059057         0.000507            0.504          0.504000               1e-16               3                 50  {'learning_rate': 1e-16, 'n_estimators': 50, '...               25           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893           0.504950            0.503893               0.50            0.504444               0.50            0.504444           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885           0.505051            0.503885      0.002964        0.000067        0.002000         0.000222\n",
       "12       0.003832         0.000303            0.805          0.829444                 0.5               1                  5  {'learning_rate': 0.5, 'n_estimators': 5, 'max...               24           0.861386            0.837597           0.861386            0.833148           0.851485            0.834260           0.772277            0.806452               0.70            0.834444               0.76            0.830000           0.808081            0.841287           0.787879            0.817980           0.838384            0.841287           0.808081            0.817980      0.000159        0.000018        0.049141         0.010958\n",
       "13       0.005865         0.000333            0.809          0.839331                 0.5               1                 10  {'learning_rate': 0.5, 'n_estimators': 10, 'ma...               22           0.881188            0.842047           0.881188            0.840934           0.841584            0.853170           0.792079            0.824249               0.68            0.851111               0.72            0.804444           0.808081            0.847947           0.797980            0.841287           0.838384            0.844617           0.848485            0.843507      0.000158        0.000035        0.062425         0.013814\n",
       "14       0.012112         0.000388            0.822          0.858775                 0.5               1                 25  {'learning_rate': 0.5, 'n_estimators': 25, 'ma...               19           0.871287            0.855395           0.871287            0.850945           0.831683            0.855395           0.841584            0.850945               0.71            0.875556               0.78            0.864444           0.787879            0.856826           0.818182            0.860155           0.868687            0.859046           0.838384            0.859046      0.000411        0.000067        0.048257         0.006819\n",
       "15       0.022031         0.000431            0.835          0.879777                 0.5               1                 50  {'learning_rate': 0.5, 'n_estimators': 50, 'ma...               16           0.871287            0.875417           0.831683            0.875417           0.861386            0.878754           0.871287            0.879867               0.76            0.887778               0.83            0.881111           0.777778            0.876804           0.838384            0.883463           0.858586            0.879023           0.848485            0.880133      0.000641        0.000051        0.036066         0.003577\n",
       "16       0.005673         0.000340            0.828          0.850220                 0.5               2                  5  {'learning_rate': 0.5, 'n_estimators': 5, 'max...               18           0.891089            0.835373           0.891089            0.848721           0.871287            0.853170           0.851485            0.847608               0.70            0.855556               0.78            0.856667           0.808081            0.850166           0.808081            0.849057           0.828283            0.853496           0.848485            0.852386      0.000201        0.000029        0.055117         0.005701\n",
       "17       0.009298         0.000350            0.834          0.871220                 0.5               2                 10  {'learning_rate': 0.5, 'n_estimators': 10, 'ma...               17           0.900990            0.866518           0.881188            0.869855           0.841584            0.867631           0.861386            0.866518               0.72            0.872222               0.77            0.876667           0.818182            0.866815           0.848485            0.885683           0.858586            0.873474           0.838384            0.866815      0.000180        0.000030        0.050756         0.005854\n",
       "18       0.020994         0.000471            0.851          0.920776                 0.5               2                 25  {'learning_rate': 0.5, 'n_estimators': 25, 'ma...                8           0.900990            0.922136           0.851485            0.915462           0.861386            0.912125           0.881188            0.925473               0.76            0.920000               0.85            0.922222           0.838384            0.926748           0.868687            0.922309           0.838384            0.928968           0.858586            0.912320      0.001028        0.000094        0.035380         0.005535\n",
       "19       0.040192         0.000514            0.868          0.966000                 0.5               2                 50  {'learning_rate': 0.5, 'n_estimators': 50, 'ma...                3           0.910891            0.963293           0.881188            0.969967           0.861386            0.967742           0.891089            0.965517               0.80            0.956667               0.86            0.968889           0.868687            0.970033           0.878788            0.963374           0.858586            0.974473           0.868687            0.960044      0.001869        0.000112        0.027401         0.005022\n",
       "20       0.007531         0.000330            0.846          0.889108                 0.5               3                  5  {'learning_rate': 0.5, 'n_estimators': 5, 'max...               11           0.891089            0.886541           0.910891            0.879867           0.891089            0.888765           0.851485            0.887653               0.74            0.894444               0.80            0.883333           0.828283            0.886792           0.828283            0.896781           0.868687            0.897891           0.848485            0.889012      0.000447        0.000019        0.047832         0.005454\n",
       "21       0.013525         0.000398            0.858          0.918331                 0.5               3                 10  {'learning_rate': 0.5, 'n_estimators': 10, 'ma...                5           0.910891            0.907675           0.891089            0.911012           0.891089            0.924360           0.871287            0.921023               0.79            0.923333               0.83            0.912222           0.848485            0.913430           0.828283            0.924528           0.858586            0.917869           0.858586            0.927858      0.001651        0.000074        0.034041         0.006530\n",
       "22       0.029832         0.000455            0.868          0.976445                 0.5               3                 25  {'learning_rate': 0.5, 'n_estimators': 25, 'ma...                3           0.891089            0.978865           0.871287            0.976641           0.861386            0.977753           0.881188            0.974416               0.82            0.981111               0.88            0.974444           0.858586            0.977802           0.848485            0.976693           0.868687            0.968923           0.898990            0.977802      0.001265        0.000046        0.021525         0.003128\n",
       "23       0.057865         0.000524            0.877          0.999778                 0.5               3                 50  {'learning_rate': 0.5, 'n_estimators': 50, 'ma...                1           0.920792            1.000000           0.871287            1.000000           0.910891            1.000000           0.881188            1.000000               0.84            1.000000               0.86            1.000000           0.868687            1.000000           0.848485            1.000000           0.878788            0.998890           0.888889            0.998890      0.002730        0.000014        0.024129         0.000444\n",
       "24       0.003916         0.000339            0.806          0.826885                   1               1                  5  {'learning_rate': 1.0, 'n_estimators': 5, 'max...               23           0.821782            0.819800           0.861386            0.816463           0.851485            0.823137           0.801980            0.819800               0.71            0.846667               0.77            0.826667           0.808081            0.820200           0.777778            0.837958           0.818182            0.830189           0.838384            0.827969      0.000112        0.000089        0.042362         0.008910\n",
       "25       0.005891         0.000387            0.815          0.842889                   1               1                 10  {'learning_rate': 1.0, 'n_estimators': 10, 'ma...               21           0.851485            0.845384           0.811881            0.842047           0.851485            0.849833           0.851485            0.842047               0.77            0.844444               0.76            0.831111           0.737374            0.841287           0.818182            0.853496           0.868687            0.837958           0.828283            0.841287      0.000192        0.000140        0.042541         0.005822\n",
       "26       0.011767         0.000356            0.822          0.876889                   1               1                 25  {'learning_rate': 1.0, 'n_estimators': 25, 'ma...               19           0.891089            0.869855           0.811881            0.882091           0.881188            0.874305           0.841584            0.875417               0.75            0.886667               0.85            0.877778           0.747475            0.874584           0.808081            0.880133           0.797980            0.875694           0.838384            0.872364      0.000104        0.000025        0.046201         0.004685\n",
       "27       0.022429         0.000450            0.837          0.900553                   1               1                 50  {'learning_rate': 1.0, 'n_estimators': 50, 'ma...               15           0.910891            0.892102           0.821782            0.903226           0.831683            0.892102           0.841584            0.897664               0.77            0.910000               0.86            0.898889           0.777778            0.904550           0.858586            0.903441           0.858586            0.905660           0.838384            0.897891      0.000858        0.000059        0.039004         0.005548\n",
       "28       0.005655         0.000371            0.839          0.864105                   1               2                  5  {'learning_rate': 1.0, 'n_estimators': 5, 'max...               14           0.881188            0.850945           0.900990            0.857620           0.831683            0.854283           0.861386            0.856507               0.74            0.873333               0.81            0.870000           0.828283            0.870144           0.838384            0.867925           0.838384            0.885683           0.858586            0.854606      0.000200        0.000059        0.041684         0.010470\n",
       "29       0.009311         0.000366            0.844          0.901997                   1               2                 10  {'learning_rate': 1.0, 'n_estimators': 10, 'ma...               13           0.861386            0.894327           0.881188            0.909900           0.841584            0.895439           0.841584            0.884316               0.79            0.908889               0.82            0.915556           0.838384            0.904550           0.858586            0.908990           0.848485            0.906770           0.858586            0.891232      0.000092        0.000033        0.023829         0.009499\n",
       "30       0.020667         0.000450            0.845          0.960555                   1               2                 25  {'learning_rate': 1.0, 'n_estimators': 25, 'ma...               12           0.871287            0.958843           0.871287            0.965517           0.841584            0.961068           0.891089            0.953281               0.76            0.960000               0.83            0.964444           0.838384            0.962264           0.848485            0.957825           0.828283            0.965594           0.868687            0.956715      0.000625        0.000098        0.034483         0.003830\n",
       "31       0.039643         0.000524            0.857          0.994666                   1               2                 50  {'learning_rate': 1.0, 'n_estimators': 50, 'ma...                6           0.861386            0.996663           0.861386            0.995551           0.841584            0.992214           0.891089            0.988877               0.81            0.996667               0.84            0.994444           0.858586            0.994451           0.878788            0.996670           0.838384            0.996670           0.888889            0.994451      0.000842        0.000075        0.024027         0.002377\n",
       "32       0.007874         0.000377            0.847          0.907111                   1               3                  5  {'learning_rate': 1.0, 'n_estimators': 5, 'max...               10           0.881188            0.911012           0.891089            0.908788           0.841584            0.896552           0.821782            0.903226               0.78            0.917778               0.83            0.912222           0.858586            0.913430           0.848485            0.900111           0.878788            0.916759           0.838384            0.891232      0.000936        0.000113        0.031309         0.008478\n",
       "33       0.013244         0.000373            0.851          0.951668                   1               3                 10  {'learning_rate': 1.0, 'n_estimators': 10, 'ma...                8           0.920792            0.959956           0.861386            0.946607           0.871287            0.946607           0.782178            0.952169               0.78            0.961111               0.86            0.958889           0.838384            0.947836           0.868687            0.947836           0.858586            0.948946           0.868687            0.946726      0.001056        0.000039        0.040229         0.005680\n",
       "34       0.029642         0.000481            0.856          0.998666                   1               3                 25  {'learning_rate': 1.0, 'n_estimators': 25, 'ma...                7           0.881188            1.000000           0.851485            0.997775           0.900990            1.000000           0.861386            0.995551               0.76            0.997778               0.84            1.000000           0.888889            0.997780           0.848485            0.998890           0.858586            1.000000           0.868687            0.998890      0.001209        0.000047        0.036742         0.001389\n",
       "35       0.055487         0.000549            0.876          1.000000                   1               3                 50  {'learning_rate': 1.0, 'n_estimators': 50, 'ma...                2           0.891089            1.000000           0.900990            1.000000           0.891089            1.000000           0.881188            1.000000               0.80            1.000000               0.89            1.000000           0.868687            1.000000           0.888889            1.000000           0.858586            1.000000           0.888889            1.000000      0.001179        0.000038        0.027878         0.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.DataFrame(bst_grid.cv_results_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for best parameters is an iterative process. You should start with coarsed-granularity and move to to more detailed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Grid-Search<a name='rgrid' />\n",
    "When the number of parameters and their values is getting big traditional grid-search approach quickly becomes ineffective. A possible solution might be to randomly pick certain parameters from their distribution. While it's not an exhaustive solution, it's worth giving a shot.\n",
    "\n",
    "Create a parameters distribution dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_dist_grid = {\n",
    "    'max_depth': [1, 2, 3, 4],\n",
    "    'gamma': [0, 0.5, 1],\n",
    "    'n_estimators': randint(1, 1001), # uniform discrete random distribution\n",
    "    'learning_rate': uniform(), # gaussian distribution\n",
    "    'subsample': uniform(), # gaussian distribution\n",
    "    'colsample_bytree': uniform() # gaussian distribution\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize `RandomizedSearchCV` to **randomly pick 10 combinations of parameters**. With this approach you can easily control the number of tested models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs_grid = RandomizedSearchCV(\n",
    "    estimator=XGBClassifier(**params_fixed, seed=seed),\n",
    "    param_distributions=params_dist_grid,\n",
    "    n_iter=100,\n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=seed),\n",
    "    scoring='accuracy',\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=342, shuffle=True),\n",
       "          error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=342, silent=1,\n",
       "       subsample=1),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=1,\n",
       "          param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x119e8ed68>, 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x119e8e588>, 'gamma': [0, 0.5, 1], 'colsample_bytree': <scipy.stats._distn_infrastructure.rv_frozen object at 0x119fe8320>, 'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x119fe8e80>, 'max_depth': [1, 2, 3, 4]},\n",
       "          pre_dispatch='2*n_jobs', random_state=342, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more time take a look at choosen parameters and their accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/data_science_tools/anaconda/envs/py3/lib/python3.5/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.62000, std: 0.11225, params: {'learning_rate': 0.24756150723102166, 'n_estimators': 5, 'gamma': 0, 'colsample_bytree': 0.065034396841929132, 'subsample': 0.11848249237448605, 'max_depth': 3},\n",
       " mean: 0.82200, std: 0.03194, params: {'learning_rate': 0.4325346125891868, 'n_estimators': 492, 'gamma': 0, 'colsample_bytree': 0.13214054942810016, 'subsample': 0.61087022642994204, 'max_depth': 1},\n",
       " mean: 0.87800, std: 0.03714, params: {'learning_rate': 0.20992824607318106, 'n_estimators': 719, 'gamma': 0, 'colsample_bytree': 0.37042173856789762, 'subsample': 0.50413311801798655, 'max_depth': 3},\n",
       " mean: 0.86400, std: 0.02845, params: {'learning_rate': 0.38076975648982458, 'n_estimators': 625, 'gamma': 1, 'colsample_bytree': 0.19015760885089361, 'subsample': 0.80580143163765727, 'max_depth': 3},\n",
       " mean: 0.59200, std: 0.06095, params: {'learning_rate': 0.76526283302535481, 'n_estimators': 188, 'gamma': 0, 'colsample_bytree': 0.46363095388213049, 'subsample': 0.0056355243866283988, 'max_depth': 1},\n",
       " mean: 0.81000, std: 0.03683, params: {'learning_rate': 0.50136727776346701, 'n_estimators': 827, 'gamma': 0.5, 'colsample_bytree': 0.34846938479484713, 'subsample': 0.74469635414532132, 'max_depth': 1},\n",
       " mean: 0.75200, std: 0.04644, params: {'learning_rate': 0.32181898059099534, 'n_estimators': 589, 'gamma': 0.5, 'colsample_bytree': 0.027059952336016435, 'subsample': 0.14306953133689981, 'max_depth': 3},\n",
       " mean: 0.86500, std: 0.03220, params: {'learning_rate': 0.60504924400983728, 'n_estimators': 275, 'gamma': 0, 'colsample_bytree': 0.60524162748245613, 'subsample': 0.73951627857069258, 'max_depth': 3},\n",
       " mean: 0.86800, std: 0.02349, params: {'learning_rate': 0.22441107616112321, 'n_estimators': 695, 'gamma': 0, 'colsample_bytree': 0.3798729645059653, 'subsample': 0.38626895174139364, 'max_depth': 4},\n",
       " mean: 0.78500, std: 0.01837, params: {'learning_rate': 0.32425694966043572, 'n_estimators': 970, 'gamma': 0, 'colsample_bytree': 0.60817417739552593, 'subsample': 0.16575363219645556, 'max_depth': 1},\n",
       " mean: 0.81400, std: 0.03222, params: {'learning_rate': 0.41858151413677791, 'n_estimators': 971, 'gamma': 0, 'colsample_bytree': 0.34825342627224587, 'subsample': 0.87804837096096633, 'max_depth': 1},\n",
       " mean: 0.85600, std: 0.02956, params: {'learning_rate': 0.6730164898324128, 'n_estimators': 893, 'gamma': 0.5, 'colsample_bytree': 0.42886562960169339, 'subsample': 0.72480870167557621, 'max_depth': 2},\n",
       " mean: 0.77700, std: 0.04593, params: {'learning_rate': 0.053159184650554692, 'n_estimators': 688, 'gamma': 0.5, 'colsample_bytree': 0.0017306007327145823, 'subsample': 0.80618103156625787, 'max_depth': 4},\n",
       " mean: 0.79100, std: 0.04007, params: {'learning_rate': 0.30095423714169522, 'n_estimators': 186, 'gamma': 0.5, 'colsample_bytree': 0.065205866332905704, 'subsample': 0.71828790105302409, 'max_depth': 2},\n",
       " mean: 0.81100, std: 0.02728, params: {'learning_rate': 0.34508603000232396, 'n_estimators': 480, 'gamma': 1, 'colsample_bytree': 0.037364252972033163, 'subsample': 0.28250625246464445, 'max_depth': 1},\n",
       " mean: 0.86300, std: 0.02838, params: {'learning_rate': 0.51582699370572482, 'n_estimators': 602, 'gamma': 0, 'colsample_bytree': 0.2226013935089316, 'subsample': 0.62245233887610629, 'max_depth': 4},\n",
       " mean: 0.84300, std: 0.03198, params: {'learning_rate': 0.23850339686903943, 'n_estimators': 666, 'gamma': 0.5, 'colsample_bytree': 0.54741270181424073, 'subsample': 0.27663765139438667, 'max_depth': 3},\n",
       " mean: 0.87300, std: 0.03085, params: {'learning_rate': 0.015966162717588328, 'n_estimators': 880, 'gamma': 0, 'colsample_bytree': 0.21808623249143, 'subsample': 0.30551233623095853, 'max_depth': 4},\n",
       " mean: 0.86000, std: 0.02208, params: {'learning_rate': 0.55376165240110575, 'n_estimators': 784, 'gamma': 1, 'colsample_bytree': 0.96952587383830235, 'subsample': 0.71758614740642246, 'max_depth': 3},\n",
       " mean: 0.84500, std: 0.03302, params: {'learning_rate': 0.014269827743751962, 'n_estimators': 543, 'gamma': 0, 'colsample_bytree': 0.66733764593916534, 'subsample': 0.58035548150474148, 'max_depth': 2},\n",
       " mean: 0.87200, std: 0.02321, params: {'learning_rate': 0.77580040509255122, 'n_estimators': 675, 'gamma': 1, 'colsample_bytree': 0.82470834473123245, 'subsample': 0.86382589076750671, 'max_depth': 2},\n",
       " mean: 0.69200, std: 0.05526, params: {'learning_rate': 0.93531898232083643, 'n_estimators': 336, 'gamma': 1, 'colsample_bytree': 0.96078855107539807, 'subsample': 0.023057769953269913, 'max_depth': 2},\n",
       " mean: 0.85600, std: 0.03301, params: {'learning_rate': 0.04489508721875779, 'n_estimators': 287, 'gamma': 0, 'colsample_bytree': 0.95152103993864079, 'subsample': 0.96683562004886525, 'max_depth': 2},\n",
       " mean: 0.83200, std: 0.03134, params: {'learning_rate': 0.53783054250825324, 'n_estimators': 777, 'gamma': 1, 'colsample_bytree': 0.42660548207608473, 'subsample': 0.26356828521857223, 'max_depth': 2},\n",
       " mean: 0.84500, std: 0.02511, params: {'learning_rate': 0.9023163920661631, 'n_estimators': 876, 'gamma': 0, 'colsample_bytree': 0.98030435457121801, 'subsample': 0.32200176702196825, 'max_depth': 2},\n",
       " mean: 0.84100, std: 0.03538, params: {'learning_rate': 0.43419038829354917, 'n_estimators': 320, 'gamma': 0.5, 'colsample_bytree': 0.58077747875774866, 'subsample': 0.22958652876195917, 'max_depth': 3},\n",
       " mean: 0.84200, std: 0.03576, params: {'learning_rate': 0.7949927281817929, 'n_estimators': 127, 'gamma': 1, 'colsample_bytree': 0.7856293762743507, 'subsample': 0.39800272538871351, 'max_depth': 4},\n",
       " mean: 0.82500, std: 0.03842, params: {'learning_rate': 0.16896535823209013, 'n_estimators': 617, 'gamma': 0, 'colsample_bytree': 0.68311223297108659, 'subsample': 0.73041058617533205, 'max_depth': 1},\n",
       " mean: 0.86900, std: 0.02690, params: {'learning_rate': 0.60068216308726841, 'n_estimators': 856, 'gamma': 0.5, 'colsample_bytree': 0.58893578097228472, 'subsample': 0.73920114522276081, 'max_depth': 2},\n",
       " mean: 0.83800, std: 0.03657, params: {'learning_rate': 0.90751851131689609, 'n_estimators': 864, 'gamma': 1, 'colsample_bytree': 0.13780252051256014, 'subsample': 0.74942075719979384, 'max_depth': 3},\n",
       " mean: 0.79000, std: 0.04414, params: {'learning_rate': 0.41987292372099638, 'n_estimators': 172, 'gamma': 0, 'colsample_bytree': 0.31362653201005031, 'subsample': 0.1233781606164811, 'max_depth': 2},\n",
       " mean: 0.79700, std: 0.06087, params: {'learning_rate': 0.41880625726002607, 'n_estimators': 3, 'gamma': 0, 'colsample_bytree': 0.80036051644182216, 'subsample': 0.14852444055416003, 'max_depth': 3},\n",
       " mean: 0.86600, std: 0.03108, params: {'learning_rate': 0.11680139778361043, 'n_estimators': 828, 'gamma': 0.5, 'colsample_bytree': 0.13448222256392894, 'subsample': 0.89378628316657027, 'max_depth': 2},\n",
       " mean: 0.87200, std: 0.03696, params: {'learning_rate': 0.55311822905970465, 'n_estimators': 996, 'gamma': 0.5, 'colsample_bytree': 0.70568169093318556, 'subsample': 0.76722199948341352, 'max_depth': 4},\n",
       " mean: 0.75400, std: 0.04597, params: {'learning_rate': 0.51851789805210202, 'n_estimators': 764, 'gamma': 0.5, 'colsample_bytree': 0.078127506508282485, 'subsample': 0.29772034116009538, 'max_depth': 4},\n",
       " mean: 0.79900, std: 0.04332, params: {'learning_rate': 0.22604362169550185, 'n_estimators': 576, 'gamma': 1, 'colsample_bytree': 0.092911125786500626, 'subsample': 0.32478647008090955, 'max_depth': 2},\n",
       " mean: 0.82600, std: 0.03455, params: {'learning_rate': 0.28602526178423104, 'n_estimators': 763, 'gamma': 0.5, 'colsample_bytree': 0.060500603752250526, 'subsample': 0.90929872543463086, 'max_depth': 1},\n",
       " mean: 0.79900, std: 0.05274, params: {'learning_rate': 0.20699229428876931, 'n_estimators': 75, 'gamma': 0.5, 'colsample_bytree': 0.17504899702163124, 'subsample': 0.083038349615957463, 'max_depth': 4},\n",
       " mean: 0.87200, std: 0.03657, params: {'learning_rate': 0.60691277287419931, 'n_estimators': 662, 'gamma': 0.5, 'colsample_bytree': 0.54462043380399983, 'subsample': 0.73520013461115308, 'max_depth': 3},\n",
       " mean: 0.81700, std: 0.04313, params: {'learning_rate': 0.70585169337996201, 'n_estimators': 970, 'gamma': 1, 'colsample_bytree': 0.69013060501572276, 'subsample': 0.26959832607261747, 'max_depth': 2},\n",
       " mean: 0.76800, std: 0.03156, params: {'learning_rate': 0.83145824201435836, 'n_estimators': 351, 'gamma': 0, 'colsample_bytree': 0.96181730861058412, 'subsample': 0.35118433464283449, 'max_depth': 1},\n",
       " mean: 0.83300, std: 0.03827, params: {'learning_rate': 0.16943639142857481, 'n_estimators': 171, 'gamma': 0, 'colsample_bytree': 0.84888892715144482, 'subsample': 0.61353337454082091, 'max_depth': 1},\n",
       " mean: 0.74900, std: 0.03869, params: {'learning_rate': 0.42392831028939215, 'n_estimators': 85, 'gamma': 0.5, 'colsample_bytree': 0.15907580671899058, 'subsample': 0.065307086382955348, 'max_depth': 1},\n",
       " mean: 0.84200, std: 0.02964, params: {'learning_rate': 0.73659169978463823, 'n_estimators': 742, 'gamma': 0.5, 'colsample_bytree': 0.12720122991821681, 'subsample': 0.59381538371670528, 'max_depth': 2},\n",
       " mean: 0.87000, std: 0.03401, params: {'learning_rate': 0.12245745743134928, 'n_estimators': 419, 'gamma': 1, 'colsample_bytree': 0.52132856559778107, 'subsample': 0.48831719352338554, 'max_depth': 2},\n",
       " mean: 0.82700, std: 0.04360, params: {'learning_rate': 0.019013169365516558, 'n_estimators': 946, 'gamma': 0.5, 'colsample_bytree': 0.52417181655631517, 'subsample': 0.60987113689555739, 'max_depth': 1},\n",
       " mean: 0.82600, std: 0.03367, params: {'learning_rate': 0.54674527567161879, 'n_estimators': 111, 'gamma': 0.5, 'colsample_bytree': 0.67130192819716505, 'subsample': 0.56483192987489828, 'max_depth': 1},\n",
       " mean: 0.84800, std: 0.03056, params: {'learning_rate': 0.9622594737743404, 'n_estimators': 129, 'gamma': 1, 'colsample_bytree': 0.91942181154475899, 'subsample': 0.6372091818441632, 'max_depth': 2},\n",
       " mean: 0.88100, std: 0.02155, params: {'learning_rate': 0.22800333163252395, 'n_estimators': 648, 'gamma': 0, 'colsample_bytree': 0.67540866944413214, 'subsample': 0.43576667738277131, 'max_depth': 4},\n",
       " mean: 0.73500, std: 0.03597, params: {'learning_rate': 0.64353010001160305, 'n_estimators': 192, 'gamma': 0.5, 'colsample_bytree': 0.15852842041802295, 'subsample': 0.10669012117628052, 'max_depth': 1},\n",
       " mean: 0.77000, std: 0.02583, params: {'learning_rate': 0.48321520009662577, 'n_estimators': 933, 'gamma': 0, 'colsample_bytree': 0.025980915983675024, 'subsample': 0.46282622266807072, 'max_depth': 3},\n",
       " mean: 0.75500, std: 0.04611, params: {'learning_rate': 0.69259026056667661, 'n_estimators': 754, 'gamma': 0, 'colsample_bytree': 0.12936438191081456, 'subsample': 0.13207322963848778, 'max_depth': 2},\n",
       " mean: 0.84800, std: 0.03906, params: {'learning_rate': 0.16459096754349534, 'n_estimators': 185, 'gamma': 0.5, 'colsample_bytree': 0.90237357294287124, 'subsample': 0.1149135131077742, 'max_depth': 3},\n",
       " mean: 0.80900, std: 0.03593, params: {'learning_rate': 0.75643346980007331, 'n_estimators': 788, 'gamma': 1, 'colsample_bytree': 0.73999309494660559, 'subsample': 0.22989707709750751, 'max_depth': 2},\n",
       " mean: 0.84500, std: 0.02690, params: {'learning_rate': 0.19782370344184108, 'n_estimators': 375, 'gamma': 0, 'colsample_bytree': 0.74196255988646087, 'subsample': 0.14492255521087272, 'max_depth': 4},\n",
       " mean: 0.87600, std: 0.02682, params: {'learning_rate': 0.026090948956925764, 'n_estimators': 858, 'gamma': 0, 'colsample_bytree': 0.33473414668950685, 'subsample': 0.30855655772807611, 'max_depth': 3},\n",
       " mean: 0.77100, std: 0.05406, params: {'learning_rate': 0.026293094084396507, 'n_estimators': 542, 'gamma': 1, 'colsample_bytree': 0.097129260117515437, 'subsample': 0.084706179122562508, 'max_depth': 3},\n",
       " mean: 0.86900, std: 0.02493, params: {'learning_rate': 0.27215993259749949, 'n_estimators': 155, 'gamma': 0.5, 'colsample_bytree': 0.46601911223286829, 'subsample': 0.77187175350917425, 'max_depth': 2},\n",
       " mean: 0.78000, std: 0.02961, params: {'learning_rate': 0.56085523271120241, 'n_estimators': 921, 'gamma': 0, 'colsample_bytree': 0.019635053190330098, 'subsample': 0.83086935694362662, 'max_depth': 4},\n",
       " mean: 0.79200, std: 0.02655, params: {'learning_rate': 0.88263915010544469, 'n_estimators': 373, 'gamma': 0, 'colsample_bytree': 0.30222012208545879, 'subsample': 0.20492910218159721, 'max_depth': 2},\n",
       " mean: 0.71000, std: 0.04921, params: {'learning_rate': 0.68523190366716447, 'n_estimators': 710, 'gamma': 0.5, 'colsample_bytree': 0.38074652010804522, 'subsample': 0.073118149995856196, 'max_depth': 1},\n",
       " mean: 0.74300, std: 0.03758, params: {'learning_rate': 0.7904219886137076, 'n_estimators': 952, 'gamma': 1, 'colsample_bytree': 0.17699034320789264, 'subsample': 0.099502853870907737, 'max_depth': 2},\n",
       " mean: 0.84500, std: 0.04662, params: {'learning_rate': 0.6489622209916911, 'n_estimators': 90, 'gamma': 0, 'colsample_bytree': 0.64538146412069619, 'subsample': 0.71729823190588626, 'max_depth': 2},\n",
       " mean: 0.82700, std: 0.04506, params: {'learning_rate': 0.15001375427002706, 'n_estimators': 73, 'gamma': 0.5, 'colsample_bytree': 0.21862382069258146, 'subsample': 0.32365875972294811, 'max_depth': 1},\n",
       " mean: 0.86800, std: 0.02003, params: {'learning_rate': 0.38352477447460831, 'n_estimators': 327, 'gamma': 0.5, 'colsample_bytree': 0.89973301493921076, 'subsample': 0.70521022403953781, 'max_depth': 2},\n",
       " mean: 0.63000, std: 0.05776, params: {'learning_rate': 0.98074213450627179, 'n_estimators': 840, 'gamma': 0, 'colsample_bytree': 0.82745943484937645, 'subsample': 0.0070958765491518916, 'max_depth': 3},\n",
       " mean: 0.86600, std: 0.02540, params: {'learning_rate': 0.2702093627098191, 'n_estimators': 730, 'gamma': 0, 'colsample_bytree': 0.20232884924216632, 'subsample': 0.83911487102172, 'max_depth': 2},\n",
       " mean: 0.82100, std: 0.03402, params: {'learning_rate': 0.43595312942991182, 'n_estimators': 893, 'gamma': 0.5, 'colsample_bytree': 0.75892945117852739, 'subsample': 0.93196485616463798, 'max_depth': 1},\n",
       " mean: 0.86200, std: 0.03415, params: {'learning_rate': 0.45976633110417042, 'n_estimators': 417, 'gamma': 1, 'colsample_bytree': 0.63530299595511164, 'subsample': 0.47199410470903891, 'max_depth': 2},\n",
       " mean: 0.87300, std: 0.02706, params: {'learning_rate': 0.086735270242683016, 'n_estimators': 881, 'gamma': 0.5, 'colsample_bytree': 0.63171436790249103, 'subsample': 0.4025895046450445, 'max_depth': 2},\n",
       " mean: 0.83700, std: 0.03901, params: {'learning_rate': 0.23649191416687532, 'n_estimators': 941, 'gamma': 1, 'colsample_bytree': 0.37016926105103098, 'subsample': 0.15734295091728401, 'max_depth': 4},\n",
       " mean: 0.85600, std: 0.01977, params: {'learning_rate': 0.64788584563709217, 'n_estimators': 913, 'gamma': 0, 'colsample_bytree': 0.3940255142601945, 'subsample': 0.79003971194000089, 'max_depth': 4},\n",
       " mean: 0.86100, std: 0.02673, params: {'learning_rate': 0.16469217470793096, 'n_estimators': 505, 'gamma': 0, 'colsample_bytree': 0.415071774582214, 'subsample': 0.75355982585229708, 'max_depth': 2},\n",
       " mean: 0.86200, std: 0.01884, params: {'learning_rate': 0.62138827003131425, 'n_estimators': 661, 'gamma': 0, 'colsample_bytree': 0.86086071248045137, 'subsample': 0.68123161150478873, 'max_depth': 2},\n",
       " mean: 0.83700, std: 0.03392, params: {'learning_rate': 0.16517408188453553, 'n_estimators': 828, 'gamma': 0.5, 'colsample_bytree': 0.52481444997307547, 'subsample': 0.79100765485684121, 'max_depth': 1},\n",
       " mean: 0.84200, std: 0.02459, params: {'learning_rate': 0.15814015145175986, 'n_estimators': 837, 'gamma': 0.5, 'colsample_bytree': 0.91670997030544732, 'subsample': 0.16114455548983686, 'max_depth': 3},\n",
       " mean: 0.85700, std: 0.02567, params: {'learning_rate': 0.29619651937100966, 'n_estimators': 166, 'gamma': 0.5, 'colsample_bytree': 0.14588802855605443, 'subsample': 0.94516012980375763, 'max_depth': 3},\n",
       " mean: 0.76700, std: 0.04510, params: {'learning_rate': 0.99329554204999826, 'n_estimators': 274, 'gamma': 0, 'colsample_bytree': 0.6141536746104107, 'subsample': 0.34561084788927776, 'max_depth': 1},\n",
       " mean: 0.87600, std: 0.02302, params: {'learning_rate': 0.30600553116799611, 'n_estimators': 455, 'gamma': 1, 'colsample_bytree': 0.55792075364683469, 'subsample': 0.65792716707530496, 'max_depth': 3},\n",
       " mean: 0.80900, std: 0.03019, params: {'learning_rate': 0.73943593252450224, 'n_estimators': 925, 'gamma': 0.5, 'colsample_bytree': 0.44637862530852468, 'subsample': 0.69358816855360095, 'max_depth': 1},\n",
       " mean: 0.76900, std: 0.03848, params: {'learning_rate': 0.98940438569825906, 'n_estimators': 565, 'gamma': 0.5, 'colsample_bytree': 0.13350516754249875, 'subsample': 0.34246883215537249, 'max_depth': 3},\n",
       " mean: 0.83200, std: 0.03398, params: {'learning_rate': 0.30409600374136125, 'n_estimators': 925, 'gamma': 0.5, 'colsample_bytree': 0.74405550624713479, 'subsample': 0.96447056832601807, 'max_depth': 1},\n",
       " mean: 0.83000, std: 0.03284, params: {'learning_rate': 0.74561396253774748, 'n_estimators': 42, 'gamma': 0.5, 'colsample_bytree': 0.43463411770600047, 'subsample': 0.48793462730187975, 'max_depth': 3},\n",
       " mean: 0.79200, std: 0.03071, params: {'learning_rate': 0.51394046915789693, 'n_estimators': 966, 'gamma': 1, 'colsample_bytree': 0.83900888420844333, 'subsample': 0.15787045556793078, 'max_depth': 2},\n",
       " mean: 0.76900, std: 0.04595, params: {'learning_rate': 0.98368938914766924, 'n_estimators': 35, 'gamma': 1, 'colsample_bytree': 0.78161901107238108, 'subsample': 0.18773356110686301, 'max_depth': 1},\n",
       " mean: 0.84900, std: 0.04084, params: {'learning_rate': 0.36471605899800641, 'n_estimators': 10, 'gamma': 0.5, 'colsample_bytree': 0.5020300194037135, 'subsample': 0.54868413271278904, 'max_depth': 2},\n",
       " mean: 0.78200, std: 0.03087, params: {'learning_rate': 0.78548122504032125, 'n_estimators': 477, 'gamma': 1, 'colsample_bytree': 0.029345895229109242, 'subsample': 0.79135544908349387, 'max_depth': 4},\n",
       " mean: 0.82000, std: 0.04061, params: {'learning_rate': 0.36925420904014472, 'n_estimators': 23, 'gamma': 1, 'colsample_bytree': 0.42461134031653414, 'subsample': 0.49988329785256946, 'max_depth': 1},\n",
       " mean: 0.82300, std: 0.03713, params: {'learning_rate': 0.58266783581432036, 'n_estimators': 447, 'gamma': 0.5, 'colsample_bytree': 0.11259776013635792, 'subsample': 0.96828249382727438, 'max_depth': 1},\n",
       " mean: 0.80000, std: 0.03203, params: {'learning_rate': 0.87787928523952374, 'n_estimators': 907, 'gamma': 1, 'colsample_bytree': 0.17514923671159988, 'subsample': 0.29284404354761495, 'max_depth': 3},\n",
       " mean: 0.81900, std: 0.03561, params: {'learning_rate': 0.84294855405747193, 'n_estimators': 42, 'gamma': 0.5, 'colsample_bytree': 0.8607733929484459, 'subsample': 0.66035243129388266, 'max_depth': 1},\n",
       " mean: 0.72400, std: 0.03386, params: {'learning_rate': 0.88697512797720102, 'n_estimators': 391, 'gamma': 0.5, 'colsample_bytree': 0.33610402658503669, 'subsample': 0.040163128426996542, 'max_depth': 1},\n",
       " mean: 0.85000, std: 0.03859, params: {'learning_rate': 0.93404043122568303, 'n_estimators': 459, 'gamma': 0, 'colsample_bytree': 0.1427110872694175, 'subsample': 0.9099284219574344, 'max_depth': 2},\n",
       " mean: 0.71000, std: 0.05717, params: {'learning_rate': 0.58544745552536714, 'n_estimators': 477, 'gamma': 0, 'colsample_bytree': 0.087696062092437632, 'subsample': 0.11824594916908515, 'max_depth': 3},\n",
       " mean: 0.80100, std: 0.04413, params: {'learning_rate': 0.8999052081804112, 'n_estimators': 655, 'gamma': 1, 'colsample_bytree': 0.98566213043654705, 'subsample': 0.34352867625999006, 'max_depth': 3},\n",
       " mean: 0.89000, std: 0.03177, params: {'learning_rate': 0.22673587222022618, 'n_estimators': 819, 'gamma': 0.5, 'colsample_bytree': 0.29636511900820761, 'subsample': 0.79469453690309411, 'max_depth': 3},\n",
       " mean: 0.84200, std: 0.05412, params: {'learning_rate': 0.080040262971524556, 'n_estimators': 29, 'gamma': 1, 'colsample_bytree': 0.54650845214864119, 'subsample': 0.29838796310162563, 'max_depth': 2},\n",
       " mean: 0.80600, std: 0.03078, params: {'learning_rate': 0.82037332037678079, 'n_estimators': 36, 'gamma': 1, 'colsample_bytree': 0.32758384646402006, 'subsample': 0.31753571550134707, 'max_depth': 3},\n",
       " mean: 0.78900, std: 0.05510, params: {'learning_rate': 0.47976216654788462, 'n_estimators': 98, 'gamma': 0.5, 'colsample_bytree': 0.51522594905157182, 'subsample': 0.10894076186231982, 'max_depth': 4},\n",
       " mean: 0.83800, std: 0.03916, params: {'learning_rate': 0.64099934659490998, 'n_estimators': 649, 'gamma': 0.5, 'colsample_bytree': 0.50605061253735184, 'subsample': 0.30276543849066462, 'max_depth': 4}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_grid.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also some handy properties allowing to quickly analyze best estimator, parameters and obtained score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy obtained: 0.89\n",
      "Parameters:\n",
      "\tlearning_rate: 0.22673587222022618\n",
      "\tn_estimators: 819\n",
      "\tgamma: 0.5\n",
      "\tcolsample_bytree: 0.2963651190082076\n",
      "\tsubsample: 0.7946945369030941\n",
      "\tmax_depth: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Best accuracy obtained: {0}\".format(rs_grid.best_score_))\n",
    "print(\"Parameters:\")\n",
    "for key, value in rs_grid.best_params_.items():\n",
    "    print(\"\\t{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.29636511900820761, gamma=0.5,\n",
       "       learning_rate=0.22673587222022618, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=819, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=342, silent=1,\n",
       "       subsample=0.79469453690309411)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(accuracy_score)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_grid.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
